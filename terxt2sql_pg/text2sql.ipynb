{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af2e65eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ae1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e4406a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x114fdc580; dsn: 'user=treduser password=xxx dbname=studio_genai host=10.64.52.5 port=5432', closed: 0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_postgres_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=os.getenv(\"POSTGRES_HOST\"),\n",
    "            port=os.getenv(\"POSTGRES_PORT\"),\n",
    "            dbname=os.getenv(\"POSTGRES_DB\"),\n",
    "            user=os.getenv(\"POSTGRES_USER\"),\n",
    "            password=os.getenv(\"POSTGRES_PASSWORD\")\n",
    "        )\n",
    "        return conn\n",
    "    except OperationalError as e:\n",
    "        print(f\"Database connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "get_postgres_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ecffa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./metadata/causal_inference_metadata.txt'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b7c69431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matadata():\n",
    "    metadata_file_path = os.path.join(os.curdir, \"metadata\", \"causal_inference_metadata.txt\")\n",
    "    try:\n",
    "        with open(metadata_file_path, \"r\") as f:\n",
    "            data = f.read()\n",
    "            print(data)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\")\n",
    "        return None\n",
    "    #     print(\"Invalid JSON format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8a88d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    \"\"\"\n",
    "    Initialize and return Azure OpenAI client.\n",
    "    \n",
    "    Requires environment variables:\n",
    "    - AZURE_OPENAI_API_KEY: Your Azure OpenAI API key\n",
    "    - AZURE_OPENAI_ENDPOINT: Your Azure OpenAI endpoint URL\n",
    "    - AZURE_OPENAI_DEPLOYMENT_NAME: Your deployment name (model name)\n",
    "    - AZURE_OPENAI_API_VERSION: API version\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "        )\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize Azure OpenAI client: {e}\")\n",
    "        print(\"Please ensure the following environment variables are set:\")\n",
    "        print(\"- AZURE_OPENAI_API_KEY\")\n",
    "        print(\"- AZURE_OPENAI_ENDPOINT\")\n",
    "        print(\"- AZURE_OPENAI_DEPLOYMENT_NAME (optional, can be passed when making calls)\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f9223d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(input_text):\n",
    "    metadata = get_matadata()\n",
    "\n",
    "    sys_prompt = \"\"\"\n",
    "    You are an expert SQL query generator.\n",
    "You will be given:\n",
    "A natural language question\n",
    "Database metadata (tables, columns, data types, relationships)\n",
    "Your task is to generate only a single valid SQL query that answers the question.\n",
    "Mandatory Rules:\n",
    "Always fully qualify table names using the causal_inference schema\n",
    "(e.g., causal_inference.table_name)\n",
    "Never assume or use the public schema\n",
    "Use only tables and columns explicitly defined in the metadata\n",
    "Infer joins strictly from provided relationships\n",
    "Do not add assumptions or fabricate fields\n",
    "Do not include explanations, comments, markdown, or extra text\n",
    "Output only executable SQL\n",
    "Use ANSI SQL unless otherwise specified\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Question: {input_text}\n",
    "    Database schema metadata: {metadata}\n",
    "    \"\"\"\n",
    "\n",
    "    llm_obj = get_llm()\n",
    "    response = llm_obj.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )   \n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c844de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql_query(sql_query):\n",
    "    \"\"\"\n",
    "    Validate a SQL query using LLM and return binary result (True/False).\n",
    "    \n",
    "    This function:\n",
    "    - Removes markdown code blocks (```sql ... ```)\n",
    "    - Uses LLM to validate SQL against database schema\n",
    "    - Returns True if valid, False if invalid\n",
    "    \n",
    "    Args:\n",
    "        sql_query: Raw SQL query string (may contain markdown formatting)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_valid: bool, cleaned_query: str)\n",
    "            - is_valid: True if query is valid, False otherwise\n",
    "            - cleaned_query: Cleaned SQL query string\n",
    "    \"\"\"\n",
    "    if not sql_query or not isinstance(sql_query, str):\n",
    "        return False, \"\"\n",
    "    \n",
    "    # Remove markdown code blocks if present\n",
    "    cleaned_query = sql_query.strip()\n",
    "    \n",
    "    # Remove markdown code fences (```sql, ```, etc.)\n",
    "    if cleaned_query.startswith('```'):\n",
    "        # Find the first newline after ```\n",
    "        first_newline = cleaned_query.find('\\n')\n",
    "        if first_newline != -1:\n",
    "            cleaned_query = cleaned_query[first_newline + 1:]\n",
    "        else:\n",
    "            # No newline, just remove the ```\n",
    "            cleaned_query = cleaned_query[3:]\n",
    "    \n",
    "    # Remove closing ```\n",
    "    if cleaned_query.endswith('```'):\n",
    "        cleaned_query = cleaned_query[:-3]\n",
    "    \n",
    "    # Strip whitespace\n",
    "    cleaned_query = cleaned_query.strip()\n",
    "    \n",
    "    # Basic validation - check if query is empty\n",
    "    if not cleaned_query:\n",
    "        return False, cleaned_query\n",
    "    \n",
    "    # Get metadata for validation\n",
    "    metadata = get_matadata()\n",
    "    llm_obj = get_llm()\n",
    "    \n",
    "    sys_prompt = \"\"\"\n",
    "    You are an expert SQL validator. Your task is to validate SQL queries against a database schema.\n",
    "    \n",
    "    Analyze the provided SQL query and check:\n",
    "    1. Syntax correctness (valid SQL syntax)\n",
    "    2. Schema compliance (tables and columns exist in the metadata)\n",
    "    3. Schema qualification (tables use causal_inference schema)\n",
    "    4. Column existence (all referenced columns exist in their respective tables)\n",
    "    5. Join correctness (joins are valid based on relationships)\n",
    "    6. Data type compatibility (operations are compatible with column types)\n",
    "    \n",
    "    Respond with ONLY a single word: \"VALID\" if the query is valid, or \"INVALID\" if it has any issues.\n",
    "    Do not provide explanations, just the single word response.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Database schema metadata:\n",
    "    {metadata}\n",
    "    \n",
    "    SQL Query to validate:\n",
    "    {cleaned_query}\n",
    "    \n",
    "    Is this SQL query valid? Respond with only \"VALID\" or \"INVALID\".\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm_obj.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.1  # Low temperature for consistent validation\n",
    "        )\n",
    "        \n",
    "        validation_result = response.choices[0].message.content.strip().upper()\n",
    "        \n",
    "        # Check if response indicates valid query\n",
    "        is_valid = \"VALID\" in validation_result and \"INVALID\" not in validation_result\n",
    "        \n",
    "        return is_valid, cleaned_query\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM validation: {e}\")\n",
    "        # Fallback: return False if LLM validation fails\n",
    "        return False, cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8965b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql_query):\n",
    "    \"\"\"\n",
    "    Execute a SQL query and return the results.\n",
    "    \n",
    "    Args:\n",
    "        sql_query: SQL query string to execute (will be validated and cleaned)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries, where each dictionary represents a row\n",
    "              with column names as keys\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the SQL query is invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = get_postgres_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        \n",
    "        # Get column names\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        \n",
    "        # Fetch all rows and convert to list of dictionaries\n",
    "        rows = cursor.fetchall()\n",
    "        results = [dict(zip(columns, row)) for row in rows]\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        print(f\"Query: {sql_query}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85051c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data):\n",
    "    \"\"\"\n",
    "    Generate a concise 4-5 line summary of the given data using LLM.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries representing query results, or pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        str: A 4-5 line summary of the data insights\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return \"No data available to summarize.\"\n",
    "    \n",
    "    # Convert to DataFrame if it's a list of dictionaries\n",
    "    if isinstance(data, list):\n",
    "        df = pd.DataFrame(data)\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        df = data.copy()\n",
    "    else:\n",
    "        return \"Invalid data format. Expected list of dictionaries or DataFrame.\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"The query returned no results.\"\n",
    "    \n",
    "    # Get basic statistics about the data\n",
    "    num_rows = len(df)\n",
    "    num_cols = len(df.columns)\n",
    "    column_names = list(df.columns)\n",
    "    \n",
    "    # Convert data to a readable format for LLM\n",
    "    # Limit to first 10 rows to avoid token limits\n",
    "    sample_data = df.head(10).to_dict('records')\n",
    "    \n",
    "    # Get summary statistics for numeric columns\n",
    "    numeric_summary = {}\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        numeric_summary[col] = {\n",
    "            'min': float(df[col].min()),\n",
    "            'max': float(df[col].max()),\n",
    "            'mean': float(df[col].mean()),\n",
    "            'sum': float(df[col].sum())\n",
    "        }\n",
    "    \n",
    "    llm_obj = get_llm()\n",
    "    \n",
    "    sys_prompt = \"\"\"\n",
    "    You are a data analyst expert. Your task is to analyze query results and generate a concise,\n",
    "    insightful summary in exactly 4-5 lines.\n",
    "    \n",
    "    Rules:\n",
    "    - Write exactly 4 lines (not more, not less)\n",
    "    - Focus on key insights, trends, and important findings\n",
    "    - Use clear, business-friendly language\n",
    "    - Highlight the most significant data points\n",
    "    - If there are comparisons (e.g., historical vs current), emphasize the differences\n",
    "    - Be specific with numbers when relevant\n",
    "    - Do not include markdown formatting or bullet points\n",
    "    - Write in paragraph form, with each line being a complete sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following query results and generate a 4-5 line summary:\n",
    "    \n",
    "    Data Overview:\n",
    "    - Number of rows: {num_rows}\n",
    "    - Number of columns: {num_cols}\n",
    "    - Column names: {', '.join(column_names)}\n",
    "    \n",
    "    Sample data (first {min(10, num_rows)} rows):\n",
    "    {json.dumps(sample_data, indent=2, default=str)}\n",
    "    \n",
    "    Numeric column statistics:\n",
    "    {json.dumps(numeric_summary, indent=2) if numeric_summary else \"No numeric columns\"}\n",
    "    \n",
    "    Generate a concise 4-5 line summary that highlights the key insights from this data.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm_obj.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.3  # Moderate temperature for balanced creativity and consistency\n",
    "        )\n",
    "        \n",
    "        summary = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Ensure it's approximately 4-5 lines (split by periods or newlines)\n",
    "        lines = [line.strip() for line in summary.split('\\n') if line.strip()]\n",
    "        if len(lines) < 4:\n",
    "            # If too few lines, try splitting by sentences\n",
    "            sentences = [s.strip() for s in summary.split('.') if s.strip()]\n",
    "            if len(sentences) >= 4:\n",
    "                summary = '. '.join(sentences[:5]) + '.' if len(sentences) > 5 else '. '.join(sentences) + '.'\n",
    "        elif len(lines) > 5:\n",
    "            # If too many lines, take first 5\n",
    "            summary = '\\n'.join(lines[:5])\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        # Fallback to basic summary\n",
    "        return f\"Query returned {num_rows} rows with {num_cols} columns: {', '.join(column_names)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chart():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9076f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggested_que(count=3):\n",
    "    \"\"\"\n",
    "    Generate suggested questions based on the database metadata.\n",
    "    \n",
    "    Args:\n",
    "        count: Number of suggested questions to generate (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of suggested questions as strings\n",
    "    \"\"\"\n",
    "    metadata = get_matadata()\n",
    "    llm_obj = get_llm()\n",
    "    \n",
    "    sys_prompt = \"\"\"\n",
    "    You are an expert at analyzing database schemas and generating relevant business questions.\n",
    "    Based on the provided database metadata, generate natural language questions that users might ask\n",
    "    to analyze their business data.\n",
    "    \n",
    "    Rules:\n",
    "    - Generate questions that are relevant to the tables, columns, and relationships described in the metadata\n",
    "    - Questions should be business-focused and actionable\n",
    "    - Questions should be clear and specific\n",
    "    - Each question should be on a separate line\n",
    "    - Do not include numbering, bullets, or markdown formatting\n",
    "    - Output only the questions, one per line\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Database schema metadata: {metadata}\n",
    "    \n",
    "    Generate exactly {count} relevant business questions that can be answered using this database.\n",
    "    Output only the questions, one per line, without any numbering or formatting.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm_obj.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract questions from response\n",
    "        questions_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Split by newlines and clean up\n",
    "        questions = [q.strip() for q in questions_text.split('\\n') if q.strip()]\n",
    "        \n",
    "        # Remove any numbering or bullets if present\n",
    "        questions = [q.lstrip('0123456789.-) ').strip() for q in questions]\n",
    "        \n",
    "        # Return the requested number of questions\n",
    "        return questions[:count]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating suggested questions: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85a25039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do historical sales compare to current year sales for the \"Beverages\" category across all stores?\n",
      "What is the impact of customer footfall on daily sales revenue for \"Bakery and Bread\" category items?\n",
      "What promotional strategies have historically achieved the highest ROI for the \"Frozen Food\" category?\n"
     ]
    }
   ],
   "source": [
    "recommended_ques = get_suggested_que()\n",
    "for que in recommended_ques:\n",
    "    print(que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3adc574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```sql\n",
      "SELECT\n",
      "    'Historical Sales' AS sales_type,\n",
      "    SUM(transaction_amount) AS total_sales,\n",
      "    SUM(quantity) AS total_quantity\n",
      "FROM causal_inference.historical_sales\n",
      "WHERE category_id = 'Cat-01'\n",
      "UNION ALL\n",
      "SELECT\n",
      "    'Current Year Sales' AS sales_type,\n",
      "    SUM(transaction_amount) AS total_sales,\n",
      "    SUM(quantity) AS total_quantity\n",
      "FROM causal_inference.sales\n",
      "WHERE category_id = 'Cat-01';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "input_text = \"How do historical sales compare to current year sales for the Beverages category across all stores?\"\n",
    "\n",
    "conn = get_postgres_connection()\n",
    "generated_sql = generate_sql(input_text)\n",
    "print(generated_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac528971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True SELECT\n",
      "    'Historical Sales' AS sales_type,\n",
      "    SUM(transaction_amount) AS total_sales,\n",
      "    SUM(quantity) AS total_quantity\n",
      "FROM causal_inference.historical_sales\n",
      "WHERE category_id = 'Cat-01'\n",
      "UNION ALL\n",
      "SELECT\n",
      "    'Current Year Sales' AS sales_type,\n",
      "    SUM(transaction_amount) AS total_sales,\n",
      "    SUM(quantity) AS total_quantity\n",
      "FROM causal_inference.sales\n",
      "WHERE category_id = 'Cat-01';\n"
     ]
    }
   ],
   "source": [
    "# Validate and clean the SQL query using LLM\n",
    "is_valid, cleaned_query = validate_sql_query(generated_sql)\n",
    "print(is_valid, cleaned_query)\n",
    "\n",
    "if not is_valid:\n",
    "    raise ValueError(\"SQL query validation failed. The query is invalid according to the database schema.\")\n",
    "\n",
    "if not cleaned_query:\n",
    "    raise ValueError(\"SQL query is empty after cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c40eee9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_type</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Historical Sales</td>\n",
       "      <td>108084990.0</td>\n",
       "      <td>23314554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Current Year Sales</td>\n",
       "      <td>54836168.0</td>\n",
       "      <td>11828662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sales_type  total_sales  total_quantity\n",
       "0    Historical Sales  108084990.0        23314554\n",
       "1  Current Year Sales   54836168.0        11828662"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = execute_sql(cleaned_query)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "788c2b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Historical Sales significantly outperformed Current Year Sales with total sales of $108. 08 million compared to $54. 84 million. Similarly, the total quantity sold historically was 23. 31 million units, nearly double the 11.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = generate_summary(data)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c16784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart = generate_chart(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
